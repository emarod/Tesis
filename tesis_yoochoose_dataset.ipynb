{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOPSH0JRTPSoHDXQevZNHo9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emarod/Tesis/blob/main/tesis_yoochoose_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "B58WRawqkEQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O_ajuEBbuYQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = {}\n",
        "opt[\"dataset\"] = \"yoochoose_1_64_weights_pandas\"\n",
        "opt[\"batchSize\"] = 100\n",
        "opt[\"hiddenSize\"] = 100\n",
        "opt[\"epoch\"] = 30\n",
        "opt[\"lr\"] = 0.001\n",
        "opt[\"lr_dc\"] = 0.1\n",
        "opt[\"lr_dc_step\"] = 3\n",
        "opt[\"l2\"] = 1e-5\n",
        "opt[\"step\"] = 1\n",
        "opt[\"patience\"] = 10\n",
        "opt[\"nonhybrid\"] = \"store_true\"\n",
        "opt[\"validation\"] = False\n",
        "opt[\"valid_portion\"] = 0.1\n",
        "opt[\"seed\"] = 42"
      ],
      "metadata": {
        "id": "SLA9Nb9CprPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt[\"dataset\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Oiv0nmGWpsEK",
        "outputId": "71a8329b-88b7-4234-f057-dc9150741e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yoochoose_25_weights_pandas_whole_dataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_masks(all_usr_pois, item_tail):\n",
        "    us_lens = [len(upois) for upois in all_usr_pois]\n",
        "    len_max = max(us_lens)\n",
        "    us_pois = [upois + item_tail * (len_max - le) for upois, le in zip(all_usr_pois, us_lens)]\n",
        "    us_msks = [[1] * le + [0] * (len_max - le) for le in us_lens]\n",
        "    return us_pois, us_msks, len_max"
      ],
      "metadata": {
        "id": "c1FOV4zdkNcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_validation(train_set, valid_portion):\n",
        "    train_set_x, train_set_y = train_set\n",
        "    n_samples = len(train_set_x)\n",
        "    sidx = np.arange(n_samples, dtype='int32')\n",
        "    np.random.shuffle(sidx)\n",
        "    n_train = int(np.round(n_samples * (1. - valid_portion)))\n",
        "    valid_set_x = [train_set_x[s] for s in sidx[n_train:]]\n",
        "    valid_set_y = [train_set_y[s] for s in sidx[n_train:]]\n",
        "    train_set_x = [train_set_x[s] for s in sidx[:n_train]]\n",
        "    train_set_y = [train_set_y[s] for s in sidx[:n_train]]\n",
        "\n",
        "    return (train_set_x, train_set_y), (valid_set_x, valid_set_y)"
      ],
      "metadata": {
        "id": "3wC_iELHkPHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Data():\n",
        "    def __init__(self, data, shuffle=False, graph=None):\n",
        "        inputs = data[0]\n",
        "        times = data[2]\n",
        "        times, _, _ = data_masks(times, [0])\n",
        "        self.times = np.asarray(times)\n",
        "        inputs, mask, len_max = data_masks(inputs, [0]) # padding\n",
        "        self.inputs = np.asarray(inputs)\n",
        "        self.mask = np.asarray(mask)\n",
        "        self.len_max = len_max\n",
        "        self.targets = np.asarray(data[1])\n",
        "        self.length = len(inputs)\n",
        "        self.shuffle = shuffle\n",
        "        self.graph = graph\n",
        "\n",
        "    def generate_batch(self, batch_size):\n",
        "        if self.shuffle:\n",
        "            shuffled_arg = np.arange(self.length)\n",
        "            np.random.shuffle(shuffled_arg)\n",
        "            self.inputs = self.inputs[shuffled_arg]\n",
        "            self.mask = self.mask[shuffled_arg]\n",
        "            self.targets = self.targets[shuffled_arg]\n",
        "            self.times = self.times[shuffled_arg] # new addition\n",
        "        n_batch = int(self.length / batch_size)\n",
        "        if self.length % batch_size != 0:\n",
        "            n_batch += 1\n",
        "        slices = np.split(np.arange(n_batch * batch_size), n_batch)\n",
        "        slices[-1] = slices[-1][:(self.length - batch_size * (n_batch - 1))]\n",
        "        return slices\n",
        "\n",
        "    def get_slice(self, i):\n",
        "        inputs, mask, targets, times = self.inputs[i], self.mask[i], self.targets[i], self.times[i]\n",
        "        items, n_node, A, alias_inputs = [], [], [], []\n",
        "        for u_input in inputs:\n",
        "            n_node.append(len(np.unique(u_input)))\n",
        "        max_n_node = np.max(n_node)\n",
        "        for u_input, u_times in zip(inputs, times):\n",
        "            node = np.unique(u_input)\n",
        "            # u_times_normalized = np.log(u_times + 1) # new addition\n",
        "            u_times_normalized = u_times # new addition\n",
        "\n",
        "            # new addition\n",
        "            # Necesitamos el tiempo de permanencia asociado a cada nodo único.\n",
        "            node_time_map = {}\n",
        "            for item_id, time_val in zip(u_input, u_times_normalized):\n",
        "              if item_id != 0: # Ignorar padding\n",
        "                # Aquí usamos el último tiempo de permanencia si el ítem se repite,\n",
        "                # ya que la matriz A se construye sobre los nodos únicos.\n",
        "                node_time_map[item_id] = time_val\n",
        "\n",
        "            items.append(node.tolist() + (max_n_node - len(node)) * [0])\n",
        "            u_A = np.zeros((max_n_node, max_n_node))\n",
        "            for i in np.arange(len(u_input) - 1):\n",
        "                if u_input[i + 1] == 0:\n",
        "                    break\n",
        "                u = np.where(node == u_input[i])[0][0]\n",
        "                v = np.where(node == u_input[i + 1])[0][0]\n",
        "                weight = node_time_map[u_input[i]]\n",
        "                # u_A[u][v] = 1\n",
        "                u_A[u][v] = weight\n",
        "            u_sum_in = np.sum(u_A, 0)\n",
        "            u_sum_in[np.where(u_sum_in == 0)] = 1\n",
        "            u_A_in = np.divide(u_A, u_sum_in)\n",
        "            u_sum_out = np.sum(u_A, 1)\n",
        "            u_sum_out[np.where(u_sum_out == 0)] = 1\n",
        "            u_A_out = np.divide(u_A.transpose(), u_sum_out)\n",
        "            u_A = np.concatenate([u_A_in, u_A_out]).transpose()\n",
        "            A.append(u_A)\n",
        "            alias_inputs.append([np.where(node == i)[0][0] for i in u_input])\n",
        "        return alias_inputs, A, items, mask, targets"
      ],
      "metadata": {
        "id": "EGswUH80kER4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import Module, Parameter\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "SKDd1jCDkEua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(Module):\n",
        "    def __init__(self, hidden_size, step=1):\n",
        "        super(GNN, self).__init__()\n",
        "        self.step = step\n",
        "        self.hidden_size = hidden_size\n",
        "        self.input_size = hidden_size * 2\n",
        "        self.gate_size = 3 * hidden_size\n",
        "        self.w_ih = Parameter(torch.Tensor(self.gate_size, self.input_size))\n",
        "        self.w_hh = Parameter(torch.Tensor(self.gate_size, self.hidden_size))\n",
        "        self.b_ih = Parameter(torch.Tensor(self.gate_size))\n",
        "        self.b_hh = Parameter(torch.Tensor(self.gate_size))\n",
        "        self.b_iah = Parameter(torch.Tensor(self.hidden_size))\n",
        "        self.b_oah = Parameter(torch.Tensor(self.hidden_size))\n",
        "\n",
        "        self.linear_edge_in = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
        "        self.linear_edge_out = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
        "        self.linear_edge_f = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
        "\n",
        "    def GNNCell(self, A, hidden):\n",
        "        input_in = torch.matmul(A[:, :, :A.shape[1]], self.linear_edge_in(hidden)) + self.b_iah\n",
        "        input_out = torch.matmul(A[:, :, A.shape[1]: 2 * A.shape[1]], self.linear_edge_out(hidden)) + self.b_oah\n",
        "        inputs = torch.cat([input_in, input_out], 2)\n",
        "        gi = F.linear(inputs, self.w_ih, self.b_ih)\n",
        "        gh = F.linear(hidden, self.w_hh, self.b_hh)\n",
        "        i_r, i_i, i_n = gi.chunk(3, 2)\n",
        "        h_r, h_i, h_n = gh.chunk(3, 2)\n",
        "        resetgate = torch.sigmoid(i_r + h_r)\n",
        "        inputgate = torch.sigmoid(i_i + h_i)\n",
        "        newgate = torch.tanh(i_n + resetgate * h_n)\n",
        "        hy = newgate + inputgate * (hidden - newgate)\n",
        "        return hy\n",
        "\n",
        "    def forward(self, A, hidden):\n",
        "        for i in range(self.step):\n",
        "            hidden = self.GNNCell(A, hidden)\n",
        "        return hidden\n",
        "\n",
        "\n",
        "class SessionGraph(Module):\n",
        "    def __init__(self, opt, n_node):\n",
        "        super(SessionGraph, self).__init__()\n",
        "        self.hidden_size = opt[\"hiddenSize\"]\n",
        "        self.n_node = n_node\n",
        "        self.batch_size = opt[\"batchSize\"]\n",
        "        self.nonhybrid = opt[\"nonhybrid\"]\n",
        "        self.embedding = nn.Embedding(self.n_node, self.hidden_size)\n",
        "        self.gnn = GNN(self.hidden_size, step=opt[\"step\"])\n",
        "        self.linear_one = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
        "        self.linear_two = nn.Linear(self.hidden_size, self.hidden_size, bias=True)\n",
        "        self.linear_three = nn.Linear(self.hidden_size, 1, bias=False)\n",
        "        self.linear_transform = nn.Linear(self.hidden_size * 2, self.hidden_size, bias=True)\n",
        "        self.loss_function = nn.CrossEntropyLoss()\n",
        "        self.optimizer = torch.optim.Adam(self.parameters(), lr=opt[\"lr\"], weight_decay=opt[\"l2\"])\n",
        "        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=opt[\"lr_dc_step\"], gamma=opt[\"lr_dc\"])\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for weight in self.parameters():\n",
        "            weight.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def compute_scores(self, hidden, mask):\n",
        "        ht = hidden[torch.arange(mask.shape[0]).long(), torch.sum(mask, 1) - 1]  # batch_size x latent_size\n",
        "        q1 = self.linear_one(ht).view(ht.shape[0], 1, ht.shape[1])  # batch_size x 1 x latent_size\n",
        "        q2 = self.linear_two(hidden)  # batch_size x seq_length x latent_size\n",
        "        alpha = self.linear_three(torch.sigmoid(q1 + q2))\n",
        "        a = torch.sum(alpha * hidden * mask.view(mask.shape[0], -1, 1).float(), 1)\n",
        "        if not self.nonhybrid:\n",
        "            a = self.linear_transform(torch.cat([a, ht], 1))\n",
        "        b = self.embedding.weight[1:]  # n_nodes x latent_size\n",
        "        scores = torch.matmul(a, b.transpose(1, 0))\n",
        "        return scores\n",
        "\n",
        "    def forward(self, inputs, A):\n",
        "        hidden = self.embedding(inputs)\n",
        "        hidden = self.gnn(A, hidden)\n",
        "        return hidden\n",
        "\n",
        "\n",
        "def trans_to_cuda(variable):\n",
        "    if torch.cuda.is_available():\n",
        "        return variable.cuda()\n",
        "    else:\n",
        "        return variable\n",
        "\n",
        "\n",
        "def trans_to_cpu(variable):\n",
        "    if torch.cuda.is_available():\n",
        "        return variable.cpu()\n",
        "    else:\n",
        "        return variable\n",
        "\n",
        "\n",
        "def forward(model, i, data):\n",
        "    alias_inputs, A, items, mask, targets = data.get_slice(i)\n",
        "    alias_inputs = trans_to_cuda(torch.Tensor(alias_inputs).long())\n",
        "    items = trans_to_cuda(torch.Tensor(items).long())\n",
        "    A = trans_to_cuda(torch.Tensor(A).float())\n",
        "    mask = trans_to_cuda(torch.Tensor(mask).long())\n",
        "    hidden = model(items, A)\n",
        "    get = lambda i: hidden[i][alias_inputs[i]]\n",
        "    seq_hidden = torch.stack([get(i) for i in torch.arange(len(alias_inputs)).long()])\n",
        "    return targets, model.compute_scores(seq_hidden, mask)\n",
        "\n",
        "\n",
        "def train_test(model, train_data, test_data):\n",
        "    model.scheduler.step()\n",
        "    print('start training: ', datetime.datetime.now())\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    slices = train_data.generate_batch(model.batch_size)\n",
        "    for i, j in zip(slices, np.arange(len(slices))):\n",
        "        model.optimizer.zero_grad()\n",
        "        targets, scores = forward(model, i, train_data)\n",
        "        targets = trans_to_cuda(torch.Tensor(targets).long())\n",
        "        loss = model.loss_function(scores, targets - 1)\n",
        "        loss.backward()\n",
        "        model.optimizer.step()\n",
        "        total_loss += loss\n",
        "        if j % int(len(slices) / 5 + 1) == 0:\n",
        "            print('[%d/%d] Loss: %.4f' % (j, len(slices), loss.item()))\n",
        "    print('\\tLoss:\\t%.3f' % total_loss)\n",
        "\n",
        "    print('start predicting: ', datetime.datetime.now())\n",
        "    model.eval()\n",
        "    hit, mrr = [], []\n",
        "    slices = test_data.generate_batch(model.batch_size)\n",
        "    for i in slices:\n",
        "        targets, scores = forward(model, i, test_data)\n",
        "        sub_scores = scores.topk(20)[1]\n",
        "        sub_scores = trans_to_cpu(sub_scores).detach().numpy()\n",
        "        for score, target, mask in zip(sub_scores, targets, test_data.mask):\n",
        "            hit.append(np.isin(target - 1, score))\n",
        "            if len(np.where(score == target - 1)[0]) == 0:\n",
        "                mrr.append(0)\n",
        "            else:\n",
        "                mrr.append(1 / (np.where(score == target - 1)[0][0] + 1))\n",
        "    hit = np.mean(hit) * 100\n",
        "    mrr = np.mean(mrr) * 100\n",
        "    return hit, mrr"
      ],
      "metadata": {
        "id": "EmO9EYI3kRzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import time"
      ],
      "metadata": {
        "id": "Rjdl_5S0kR1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bc2958b",
        "outputId": "10341c13-f7ea-4f80-eb63-a1c9384b9b18"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b899376"
      },
      "source": [
        "Después de montar Google Drive, puedes navegar por tus archivos. Aquí te muestro cómo listar el contenido de la raíz de tu Drive para empezar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c191c36",
        "outputId": "da0766cc-20a4-49d8-a355-23bfef7305df"
      },
      "source": [
        "import os\n",
        "os.listdir('/content/drive/My Drive/Tesis/data/yoochoose_1_64_weights_pandas')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['all_train_seq.txt', 'test.txt', 'train.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc364703"
      },
      "source": [
        "Una vez que hayas localizado tu archivo, por ejemplo, un CSV llamado `mi_archivo.csv` dentro de una carpeta `MisDatos` en tu Drive, puedes cargarlo con pandas de la siguiente manera:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/drive/My Drive/Tesis/data/\""
      ],
      "metadata": {
        "id": "M05AVz-iqQgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DilJky-tsvq5",
        "outputId": "a9b6d7dd-9600-4cc4-cebb-1449507ba366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pickle.load(open(data_path + opt[\"dataset\"] + '/train.txt', 'rb'))\n",
        "if opt[\"validation\"]:\n",
        "    train_data, valid_data = split_validation(train_data, opt[\"valid_portion\"])\n",
        "    test_data = valid_data\n",
        "else:\n",
        "    test_data = pickle.load(open(data_path + opt[\"dataset\"] + '/test.txt', 'rb'))\n",
        "# all_train_seq = pickle.load(open('../datasets/' + opt[\"dataset\"] + '/all_train_seq.txt', 'rb'))\n",
        "# g = build_graph(all_train_seq)\n",
        "train_data = Data(train_data, shuffle=True)\n",
        "test_data = Data(test_data, shuffle=False)\n",
        "# del all_train_seq, g\n",
        "if opt[\"dataset\"] == 'diginetica_25' or opt[\"dataset\"] == 'diginetica_25_weights':\n",
        "    n_node = 43098\n",
        "elif opt[\"dataset\"] == 'yoochoose_25_weights' or opt[\"dataset\"] == 'yoochoose1_4' or opt[\"dataset\"] == \"yoochoose_25_weights_pandas_whole_dataset\":\n",
        "    n_node = 37484\n",
        "else:\n",
        "    n_node = 310\n",
        "    n_node = 43098\n",
        "\n",
        "model = trans_to_cuda(SessionGraph(opt, n_node))"
      ],
      "metadata": {
        "id": "WKvGVnFKkl4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting Trainning\")\n",
        "start = time.time()\n",
        "best_result = [0, 0]\n",
        "best_epoch = [0, 0]\n",
        "bad_counter = 0\n",
        "for epoch in range(opt[\"epoch\"]):\n",
        "    print('-------------------------------------------------------')\n",
        "    print('epoch: ', epoch)\n",
        "    hit, mrr = train_test(model, train_data, test_data)\n",
        "    flag = 0\n",
        "    if hit >= best_result[0]:\n",
        "        best_result[0] = hit\n",
        "        best_epoch[0] = epoch\n",
        "        flag = 1\n",
        "    if mrr >= best_result[1]:\n",
        "        best_result[1] = mrr\n",
        "        best_epoch[1] = epoch\n",
        "        flag = 1\n",
        "    print('Best Result:')\n",
        "    print('\\tRecall@20:\\t%.4f\\tMMR@20:\\t%.4f\\tEpoch:\\t%d /,\\t%d'% (best_result[0], best_result[1], epoch, opt[\"epoch\"]))\n",
        "    bad_counter += 1 - flag\n",
        "    if bad_counter >= opt[\"patience\"]:\n",
        "        print(\"Program stopped by patiente parameter\")\n",
        "        break\n",
        "print('-------------------------------------------------------')\n",
        "end = time.time()\n",
        "print(\"Run time: %f s\" % (end - start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0fOziyRkmPW",
        "outputId": "813be509-128f-47c4-936c-0044b5de2869"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Trainning\n",
            "-------------------------------------------------------\n",
            "epoch:  0\n",
            "start training:  2025-12-03 17:55:00.224618\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-2417261768.py:98: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  A = trans_to_cuda(torch.Tensor(A).float())\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0/3699] Loss: 10.6727\n",
            "[740/3699] Loss: 5.4994\n",
            "[1480/3699] Loss: 5.0951\n",
            "[2220/3699] Loss: 5.2759\n",
            "[2960/3699] Loss: 4.6868\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2417261768.py:122: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
            "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
            "  print('\\tLoss:\\t%.3f' % total_loss)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tLoss:\t20388.629\n",
            "start predicting:  2025-12-03 18:04:04.966533\n",
            "Best Result:\n",
            "\tRecall@20:\t68.2529\tMMR@20:\t28.0152\tEpoch:\t0 /,\t30\n",
            "-------------------------------------------------------\n",
            "epoch:  1\n",
            "start training:  2025-12-03 18:04:34.329346\n",
            "[0/3699] Loss: 4.1727\n",
            "[740/3699] Loss: 4.2363\n",
            "[1480/3699] Loss: 4.5280\n",
            "[2220/3699] Loss: 4.5006\n",
            "[2960/3699] Loss: 4.3483\n",
            "\tLoss:\t16379.955\n",
            "start predicting:  2025-12-03 18:13:38.685412\n",
            "Best Result:\n",
            "\tRecall@20:\t69.3477\tMMR@20:\t29.0453\tEpoch:\t1 /,\t30\n",
            "-------------------------------------------------------\n",
            "epoch:  2\n",
            "start training:  2025-12-03 18:14:07.496721\n",
            "[0/3699] Loss: 4.6472\n",
            "[740/3699] Loss: 3.6813\n",
            "[1480/3699] Loss: 3.9340\n",
            "[2220/3699] Loss: 3.8919\n",
            "[2960/3699] Loss: 3.8106\n",
            "\tLoss:\t14518.952\n",
            "start predicting:  2025-12-03 18:23:13.088065\n",
            "Best Result:\n",
            "\tRecall@20:\t70.4981\tMMR@20:\t29.7066\tEpoch:\t2 /,\t30\n",
            "-------------------------------------------------------\n",
            "epoch:  3\n",
            "start training:  2025-12-03 18:23:41.867592\n",
            "[0/3699] Loss: 4.5071\n",
            "[740/3699] Loss: 3.8002\n",
            "[1480/3699] Loss: 3.5430\n",
            "[2220/3699] Loss: 4.0885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uNKIj_ZFkmRd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}